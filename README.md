# Sagefy Functions

Este projeto Ã© uma coleÃ§Ã£o de Azure Functions desenvolvidas para processar arquivos de treinamento de dados brutos, extraindo seu conteÃºdo e gerando arquivos JSON padronizados. O objetivo principal Ã© evitar a duplicaÃ§Ã£o de conteÃºdo com a identificaÃ§Ã£o Ãºnica baseada no texto extraÃ­do.

## ğŸ›  Tecnologias Utilizadas

- **Python 3.11**
- **Azure Functions**: Plataforma serverless para executar funÃ§Ãµes sob demanda.
- **Azure Blob Storage**: Armazenamento para arquivos brutos e processados.
- **LangChain**: Utilizado para extraÃ§Ã£o de conteÃºdo de arquivos PDF, DOCX e TXT.
- **hashlib**: Para gerar IDs Ãºnicos baseados no conteÃºdo dos arquivos.
- **re**: Biblioteca padrÃ£o para manipulaÃ§Ã£o e normalizaÃ§Ã£o de texto.
- **azure-storage-blob**: Cliente Python para interaÃ§Ã£o com Azure Blob Storage.

## ğŸ“‚ Arquitetura de Pastas

```
sagefy-functions/
â”œâ”€â”€ blueprints/
â”‚   â””â”€â”€ process_training_data_func.py  # FunÃ§Ã£o principal para processar arquivos.
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ file_processor.py              # FunÃ§Ãµes para extraÃ§Ã£o de conteÃºdo dos arquivos.
â”‚   â”œâ”€â”€ generate_unique_id.py                # FunÃ§Ãµes para gerar IDs Ãºnicos baseados no conteÃºdo.
â”‚   â””â”€â”€ openai_client.py                  # FunÃ§Ãµes para interaÃ§Ã£o com a API do OpenAI.
|   â””â”€â”€ pinecone_client.py               # FunÃ§Ãµes para interaÃ§Ã£o com a API do Pinecone.
â”œâ”€â”€ models/
â”‚   â””â”€â”€ DocumentMetadata.py               # Classe para representar metadados de documentos.
â”‚   â””â”€â”€ ExtractedContent.py               # Classe para representar conteÃºdo extraÃ­do de documentos.
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ settings.py               # ConfiguraÃ§Ãµes do projeto.
â”œâ”€â”€ constants.py                       # ContÃ©m as constantes do projeto (nomes dos containers, etc.).
â”œâ”€â”€ requirements.txt                   # DependÃªncias do projeto.
â””â”€â”€ host.json                          # ConfiguraÃ§Ã£o do Azure Functions host.
```

## ğŸ“š DependÃªncias

As principais bibliotecas utilizadas no projeto estÃ£o listadas abaixo e sÃ£o instaladas via `requirements.txt`:

- `azure-functions`: SDK para criar Azure Functions.
- `azure-storage-blob`: InteraÃ§Ã£o com Azure Blob Storage.
- `azure-data-tables`: Cliente Python para interaÃ§Ã£o com o Azure Data Tables.
- `pinecone-client`: Cliente Python para interaÃ§Ã£o com a API do Pinecone.	
- `openai`: Cliente Python para interaÃ§Ã£o com a API do OpenAI.
- `langchain`: Para extraÃ§Ã£o de texto de documentos.
- `bcrypt`: Biblioteca padrÃ£o para hashing.
- `pyjwt`: Para geraÃ§Ã£o de tokens JWT.

## ğŸš€ Funcionalidades

1. **Processamento de Arquivos**:
   - Suporte a arquivos PDF, DOCX e TXT.
   - ExtraÃ§Ã£o de conteÃºdo usando LangChain.

2. **IdentificaÃ§Ã£o Ãšnica de ConteÃºdo**:
   - GeraÃ§Ã£o de IDs Ãºnicos baseados no conteÃºdo dos arquivos.
   - Ignora arquivos duplicados durante o processamento.

## ğŸ“ˆ VariÃ¡veis de Ambiente

### Principais VariÃ¡veis Utilizadas

- **`FUNCTIONS_WORKER_RUNTIME`**: Define o runtime (Python).
- **`AZURE_STORAGE_CONNECTION_STRING`**: String de conexÃ£o para o Azure Blob Storage.
- **`PINECONE_API_KEY`**: Chave de autenticaÃ§Ã£o para o Pinecone.
- **`PINECONE_INDEX_NAME`**: Nome do Ã­ndice do Pinecone.
- **`AZURE_OPENAI_API_KEY`**: Chave da API do Azure OpenAI.
- **`AZURE_OPENAI_ENDPOINT`**: Endpoint da API do Azure OpenAI.
- **`AZURE_OPENAI_MODEL`**: Modelo utilizado (por exemplo, `gpt-4o-mini`).
- **`OPENAI_API_VERSION`**: VersÃ£o da API OpenAI.
- **`OPENAI_EMBEDDING_MODEL`**: Modelo de embedding para extraÃ§Ã£o de texto.


## ğŸ”§ Como Executar

### PrÃ©-requisitos

1. **Instalar Azure Functions Core Tools**:
   - [Guia de instalaÃ§Ã£o](https://learn.microsoft.com/azure/azure-functions/functions-run-local).

2. **Configurar Ambiente Virtual**:
   ```bash
   python -m venv env
   source env/bin/activate  # Linux/Mac
   env\Scripts\activate     # Windows
   ```

3. **Instalar DependÃªncias**:
   ```bash
   pip install -r requirements.txt
   ```

### Executando Localmente

1. Iniciar o runtime local do Azure Functions:
   ```bash
   func start
   ```

2. Subir um arquivo para o container de origem no Blob Storage e observar o processamento.

### Executando testes

```bash
 python -m tests.test_chat_quality
 ```

### Como fazer deploy deploy

1. Execute o seguinte comando, substituindo `<APP_NAME>` pelo nome da sua aplicaÃ§Ã£o no Azure:
   ```bash
   func azure functionapp publish <APP_NAME> --build local
   ```


## ğŸ“ˆ Logs e Monitoramento

- **Logging**:
  - Os logs sÃ£o configurados usando a biblioteca de `logging` do Python.
  - Todas as operaÃ§Ãµes de processamento, upload e deleÃ§Ã£o de arquivos sÃ£o registradas.

- **Monitoramento no Azure**:
  - As mÃ©tricas das funÃ§Ãµes podem ser monitoradas diretamente no portal do Azure.

## ğŸ›¡ï¸ Tratamento de Erros

- Os erros durante o processamento sÃ£o registrados nos logs.
- Se o processamento falhar, o blob original nÃ£o Ã© excluÃ­do.
- Mensagens de erro detalhadas ajudam a identificar falhas relacionadas a arquivos incompatÃ­veis ou problemas de conexÃ£o.
